{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFJlSEUhxAh3",
        "outputId": "f8e875cf-7b9f-46eb-cf43-788c8b6de714"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KlG8Fujnwqi-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "from typing import List, Tuple\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Data utilities\n",
        "# -----------------------------\n",
        "class CLAPEDataset(Dataset):\n",
        "    def __init__(self, dist_dir: str, plm_dir: str, pae_dir: str,\n",
        "                 label_csv: str, file_list: List[str] = None):\n",
        "        self.dist_dir = dist_dir\n",
        "        self.plm_dir = plm_dir\n",
        "        self.pae_dir = pae_dir\n",
        "\n",
        "        # --- Load and index labels ---\n",
        "        df = pd.read_csv(label_csv, sep=\"\\t\" if label_csv.endswith(\".tsv\") else \",\")\n",
        "        self.labels = self._group_labels(df)\n",
        "\n",
        "        # collect basenames (same as before)\n",
        "        dist_files = glob.glob(os.path.join(dist_dir, \"*.csv\"))\n",
        "        basenames = [os.path.basename(p).split(\"_distances\")[0].replace(\"AF-\", \"\") for p in dist_files]\n",
        "        self.basenames = file_list or basenames\n",
        "\n",
        "    def _group_labels(self, df: pd.DataFrame) -> dict:\n",
        "        \"\"\"\n",
        "        Converts binding_sites_uniprot.csv into {uniprot_id: [(start,end),...]} dictionary.\n",
        "        Skips any rows with missing or invalid start/end values.\n",
        "        \"\"\"\n",
        "        grouped = {}\n",
        "        for uid, sub in df.groupby(\"uniprot_id\"):\n",
        "            ranges = []\n",
        "            for _, row in sub.iterrows():\n",
        "                # Skip rows with missing or non-numeric positions\n",
        "                if pd.isna(row[\"start\"]) or pd.isna(row[\"end\"]):\n",
        "                    continue\n",
        "                try:\n",
        "                    s, e = int(row[\"start\"]), int(row[\"end\"])\n",
        "                except Exception:\n",
        "                    continue\n",
        "                if e < s:\n",
        "                    s, e = e, s  # just in case of inverted ranges\n",
        "                ranges.append((s, e))\n",
        "            if ranges:\n",
        "                grouped[uid] = ranges\n",
        "        return grouped\n",
        "\n",
        "\n",
        "    def _make_label_vector(self, uniprot_id: str, n: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Create a binary vector of length n, with 1s where residues are binding sites.\n",
        "        \"\"\"\n",
        "        label_vec = np.zeros(n, dtype=np.float32)\n",
        "        if uniprot_id not in self.labels:\n",
        "            return label_vec\n",
        "        for (s, e) in self.labels[uniprot_id]:\n",
        "            s = max(s - 1, 0)  # convert 1-based â†’ 0-based indexing\n",
        "            e = min(e - 1, n - 1)\n",
        "            label_vec[s:e+1] = 1\n",
        "        return label_vec\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.basenames)\n",
        "\n",
        "    def _read_distance(self, path: str) -> np.ndarray:\n",
        "        # genfromtxt handles missing or non-numeric entries gracefully\n",
        "        arr = np.genfromtxt(path, delimiter=\",\", filling_values=np.nan)\n",
        "        # Replace NaN or inf with 0\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        return arr\n",
        "    def _read_plm(self, path: str) -> np.ndarray:\n",
        "        return np.loadtxt(path)\n",
        "\n",
        "    def _read_pae(self, path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Reads Alphafold PAE JSON files that may be:\n",
        "        - a dict with key \"predicted_aligned_error\", or\n",
        "        - a list of dicts each containing that key.\n",
        "        Returns a numeric NxN numpy array.\n",
        "        \"\"\"\n",
        "        with open(path, \"r\") as f:\n",
        "            txt = f.read()\n",
        "\n",
        "        try:\n",
        "            obj = json.loads(txt)\n",
        "        except Exception:\n",
        "            # fallback if slightly malformed JSON (e.g., single quotes)\n",
        "            obj = eval(txt)\n",
        "\n",
        "        # handle both cases\n",
        "        if isinstance(obj, list):\n",
        "            # take the first dict if it's a list of dicts\n",
        "            if len(obj) > 0 and isinstance(obj[0], dict) and \"predicted_aligned_error\" in obj[0]:\n",
        "                pae = obj[0][\"predicted_aligned_error\"]\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected PAE list structure in {path}\")\n",
        "        elif isinstance(obj, dict):\n",
        "            pae = obj.get(\"predicted_aligned_error\", None)\n",
        "            if pae is None:\n",
        "                raise ValueError(f\"No 'predicted_aligned_error' key found in dict for {path}\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected PAE object type: {type(obj)} in {path}\")\n",
        "\n",
        "        arr = np.array(pae, dtype=float)\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        base = self.basenames[idx]\n",
        "        uniprot_id = base.split(\"-\")[0]\n",
        "        # --- Distance map ---\n",
        "        dist_path = glob.glob(os.path.join(self.dist_dir, f\"AF-{base}*distances.csv\")) \\\n",
        "                    or glob.glob(os.path.join(self.dist_dir, f\"{base}*distances.csv\"))\n",
        "        if not dist_path:\n",
        "            raise FileNotFoundError(f\"No distance map found for base {base} in {self.dist_dir}\")\n",
        "        dist_path = dist_path[0]\n",
        "\n",
        "        # --- PLM matrix ---\n",
        "        plm_path = (\n",
        "            glob.glob(os.path.join(self.plm_dir, f\"{base}*_M_transformed.txt\"))\n",
        "            or glob.glob(os.path.join(self.plm_dir, f\"{base.replace('AF-', '')}*_M_transformed.txt\"))\n",
        "            or glob.glob(os.path.join(self.plm_dir, f\"{uniprot_id}-F1-model_v4_M_transformed.txt\"))  # <-- fixed\n",
        "        )\n",
        "\n",
        "        if not plm_path:\n",
        "            raise FileNotFoundError(f\"No PLM file found for base {base} (uniprot_id={uniprot_id}) in {self.plm_dir}\")\n",
        "        plm_path = plm_path[0]\n",
        "        # --- PAE matrix ---\n",
        "        pae_path = glob.glob(os.path.join(self.pae_dir, f\"{base.split('-')[0]}*_pae.txt\")) \\\n",
        "                  or glob.glob(os.path.join(self.pae_dir, f\"{base.replace('AF-', '')}*_pae.txt\")) \\\n",
        "                  or glob.glob(os.path.join(self.pae_dir, f\"*{uniprot_id}*_pae.txt\"))\n",
        "        if not pae_path:\n",
        "            raise FileNotFoundError(f\"No PAE file found for base {base} in {self.pae_dir}\")\n",
        "        pae_path = pae_path[0]\n",
        "\n",
        "        # Load data\n",
        "        dist = self._read_distance(dist_path)\n",
        "        plm = self._read_plm(plm_path)\n",
        "        pae = self._read_pae(pae_path)\n",
        "\n",
        "        # checks and normalization\n",
        "        n = dist.shape[0]\n",
        "        # Ensure all matrices are square and same size\n",
        "        for name, arr in zip([\"dist\", \"plm\", \"pae\"], [dist, plm, pae]):\n",
        "            if arr.shape[0] != arr.shape[1]:\n",
        "                raise ValueError(f\"{name} matrix not square for {base}\")\n",
        "            if arr.shape[0] != n:\n",
        "                # Handle off-by-one or small mismatches\n",
        "                diff = n - arr.shape[0]\n",
        "                if abs(diff) <= 2:\n",
        "                    if diff > 0:\n",
        "                        # pad with zeros\n",
        "                        arr = np.pad(arr, ((0, diff), (0, diff)), constant_values=0.0)\n",
        "                    else:\n",
        "                        # trim extra rows/cols\n",
        "                        arr = arr[:n, :n]\n",
        "                else:\n",
        "                    raise ValueError(\n",
        "                        f\"{name} matrix shape mismatch for {base}: expected {n}x{n}, got {arr.shape}\"\n",
        "                    )\n",
        "            # update after potential padding/trimming\n",
        "            if name == \"plm\":\n",
        "                plm = arr\n",
        "            elif name == \"pae\":\n",
        "                pae = arr\n",
        "            elif name == \"dist\":\n",
        "                dist = arr\n",
        "\n",
        "\n",
        "        dist = (dist - dist.mean()) / (dist.std() + 1e-6)\n",
        "        plm = (plm - plm.mean()) / (plm.std() + 1e-6)\n",
        "        pae = (pae - pae.mean()) / (pae.std() + 1e-6)\n",
        "\n",
        "        n = dist.shape[0]\n",
        "        label_vec = self._make_label_vector(uniprot_id, n)\n",
        "        global_label = float(label_vec.sum() > 0)\n",
        "        max_len = 1200\n",
        "        # --- Pad matrices to fixed max_len ---\n",
        "        # --- Pad label vector to same max_len ---\n",
        "        if len(label_vec) < max_len:\n",
        "            pad = max_len - len(label_vec)\n",
        "            label_vec = np.pad(label_vec, (0, pad), constant_values=0)\n",
        "        elif len(label_vec) > max_len:\n",
        "            label_vec = label_vec[:max_len]\n",
        "\n",
        "          # pick a value that fits your largest protein\n",
        "        def pad_to(t, size=max_len):\n",
        "            n = t.shape[-1]\n",
        "            if n < size:\n",
        "                pad = size - n\n",
        "                return F.pad(t, (0, pad, 0, pad), value=0.0)\n",
        "            elif n > size:\n",
        "                return t[:, :size, :size]\n",
        "            else:\n",
        "                return t\n",
        "        label_vec = torch.tensor(label_vec, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        dist = pad_to(torch.tensor(dist, dtype=torch.float32).unsqueeze(0))\n",
        "        plm  = pad_to(torch.tensor(plm,  dtype=torch.float32).unsqueeze(0))\n",
        "        pae  = pad_to(torch.tensor(pae,  dtype=torch.float32).unsqueeze(0))\n",
        "\n",
        "\n",
        "        return (\n",
        "            dist,                      # [1, max_len, max_len]\n",
        "            plm,                       # [1, max_len, max_len]\n",
        "            pae,                       # [1, max_len, max_len]\n",
        "            label_vec,  # [max_len] residue-level label\n",
        "            torch.tensor(global_label, dtype=torch.float32),  # scalar global label\n",
        "            base\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Model building blocks\n",
        "# -----------------------------\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, padding=1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class CrossAttention2D(nn.Module):\n",
        "    \"\"\"\n",
        "    Cross attention between two 2D maps. We flatten spatial dims to sequence and use MultiheadAttention.\n",
        "    Input shapes: (B, C, H, W) and (B, C, H, W) with same H=W=n.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, num_heads: int = 8, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.mha = nn.MultiheadAttention(embed_dim=channels, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm_q = nn.LayerNorm(channels)\n",
        "        self.norm_kv = nn.LayerNorm(channels)\n",
        "        self.proj = nn.Sequential(nn.Linear(channels, channels), nn.ReLU())\n",
        "\n",
        "    def forward(self, x_q, x_kv):\n",
        "        # x: (B, C, n, n) -> (B, n*n, C)\n",
        "        B, C, H, W = x_q.shape\n",
        "        seq_len = H * W\n",
        "        q = x_q.view(B, C, seq_len).permute(0, 2, 1)\n",
        "        kv = x_kv.view(B, C, seq_len).permute(0, 2, 1)\n",
        "\n",
        "        q = self.norm_q(q)\n",
        "        kv = self.norm_kv(kv)\n",
        "\n",
        "        attn_out, _ = self.mha(q, kv, kv)\n",
        "        out = self.proj(attn_out)\n",
        "        out = out.permute(0, 2, 1).view(B, C, H, W)\n",
        "        return out\n",
        "\n",
        "\n",
        "class AxialAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Applies attention along rows then along columns (axial attention).\n",
        "    Input shape: (B, C, n, n)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, num_heads: int = 8):\n",
        "        super().__init__()\n",
        "        self.row_attn = nn.MultiheadAttention(embed_dim=channels, num_heads=num_heads, batch_first=True)\n",
        "        self.col_attn = nn.MultiheadAttention(embed_dim=channels, num_heads=num_heads, batch_first=True)\n",
        "        self.ln1 = nn.LayerNorm(channels)\n",
        "        self.ln2 = nn.LayerNorm(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # row-wise: treat each row as sequence of length W, with H separate sequences -> combine batch and H\n",
        "        x_r = x.permute(0, 2, 3, 1).contiguous()  # (B, H, W, C)\n",
        "        x_r = x_r.view(B * H, W, C)\n",
        "        x_r_ln = self.ln1(x_r)\n",
        "        out_r, _ = self.row_attn(x_r_ln, x_r_ln, x_r_ln)\n",
        "        out_r = out_r.view(B, H, W, C).permute(0, 3, 1, 2)\n",
        "\n",
        "        # column-wise: treat each column as sequence of length H\n",
        "        x_c = x.permute(0, 3, 2, 1).contiguous()  # (B, W, H, C)\n",
        "        x_c = x_c.view(B * W, H, C)\n",
        "        x_c_ln = self.ln2(x_c)\n",
        "        out_c, _ = self.col_attn(x_c_ln, x_c_ln, x_c_ln)\n",
        "        out_c = out_c.view(B, W, H, C).permute(0, 3, 2, 1)\n",
        "\n",
        "        # combine\n",
        "        return out_r + out_c\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Full architecture\n",
        "# -----------------------------\n",
        "class BindingAffinityNet(nn.Module):\n",
        "    def __init__(self, base_channels: int = 32, num_heads: int = 8, K: int = 3):\n",
        "        \"\"\"\n",
        "        K is the hyperparameter requested by the user. It will be stored in the model\n",
        "        so downstream code can use it for predicting number of binding regions later.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.K = K\n",
        "\n",
        "        # initial conv encoders for distance and plm-derived matrix\n",
        "        self.conv_dist = ConvBlock(1, base_channels)\n",
        "        self.conv_plm = ConvBlock(1, base_channels)\n",
        "        self.conv_pae = ConvBlock(1, base_channels)\n",
        "\n",
        "        # three repeated blocks: convs then cross-attention both ways\n",
        "        self.repeats = nn.ModuleList()\n",
        "        for _ in range(3):\n",
        "            block = nn.ModuleDict({\n",
        "                'conv_d': ConvBlock(base_channels, base_channels),\n",
        "                'conv_p': ConvBlock(base_channels, base_channels),\n",
        "                'conv_pa': ConvBlock(base_channels, base_channels),\n",
        "                'cross_dp': CrossAttention2D(base_channels, num_heads),  # dist attends to plm\n",
        "                'cross_pd': CrossAttention2D(base_channels, num_heads),  # plm attends to dist\n",
        "            })\n",
        "            self.repeats.append(block)\n",
        "\n",
        "        # axial attention for final representations\n",
        "        self.axial_dist = AxialAttention(base_channels, num_heads)\n",
        "        self.axial_plm = AxialAttention(base_channels, num_heads)\n",
        "\n",
        "        # projection and classification head\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Conv2d(base_channels * 2, base_channels * 2, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(base_channels * 2),\n",
        "        )\n",
        "\n",
        "        # row-wise pooling (we'll pool across columns to get per-residue vectors of length n)\n",
        "        self.head_mask = nn.Sequential(\n",
        "            nn.Conv1d(base_channels * 2, base_channels, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(base_channels, 1, kernel_size=1),\n",
        "        )\n",
        "\n",
        "        # second output: a global binary label (0/1) for protein-level property\n",
        "        self.head_global = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(base_channels * 2, base_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(base_channels, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, dist, plm, pae):\n",
        "        # dist/plm/pae: (B, 1, n, n)\n",
        "        d = self.conv_dist(dist)\n",
        "        p = self.conv_plm(plm)\n",
        "        pa = self.conv_pae(pae)\n",
        "\n",
        "        # three repeats\n",
        "        for block in self.repeats:\n",
        "            d = block['conv_d'](d)\n",
        "            p = block['conv_p'](p)\n",
        "            pa = block['conv_pa'](pa)\n",
        "\n",
        "            # cross attention between dist and plm (both directions)\n",
        "            d_att = block['cross_dp'](d, p)\n",
        "            p_att = block['cross_pd'](p, d)\n",
        "\n",
        "            # residual style\n",
        "            d = d + d_att\n",
        "            p = p + p_att\n",
        "            # optionally mix pae as auxiliary skip\n",
        "            pa = pa + 0.5 * (d_att + p_att)\n",
        "\n",
        "        # axial attention on dist and plm\n",
        "        d_ax = self.axial_dist(d)\n",
        "        p_ax = self.axial_plm(p)\n",
        "\n",
        "        # concat and project\n",
        "        concat = torch.cat([d_ax, p_ax], dim=1)\n",
        "        x = self.proj(concat)\n",
        "\n",
        "        # row-wise pooling: for each residue i (row i) we pool across columns\n",
        "        # x shape (B, C, n, n) -> permute to (B, C, n, n) then treat columns as sequence for conv1d\n",
        "        B, C, n, _ = x.shape\n",
        "        row_vectors = x.mean(dim=3)  # average across columns -> (B, C, n)\n",
        "\n",
        "        mask_logits = self.head_mask(row_vectors)  # expects (B, C, n) -> output (B, 1, n)\n",
        "        mask_logits = mask_logits.squeeze(1)  # (B, n)\n",
        "\n",
        "        global_logit = self.head_global(x)  # (B, 1)\n",
        "\n",
        "        return mask_logits, global_logit.squeeze(1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Losses\n",
        "# -----------------------------\n",
        "class FocalLoss(nn.Module):\n",
        "    # Binary focal loss for logits\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # logits: (B, n) or (B,)  targets: same shape 0/1\n",
        "        prob = torch.sigmoid(logits)\n",
        "        p_t = prob * targets + (1 - prob) * (1 - targets)\n",
        "        alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "        focal_weight = alpha_factor * ((1 - p_t) ** self.gamma)\n",
        "        bce = F.binary_cross_entropy_with_logits(logits, targets.float(), reduction='none')\n",
        "        loss = focal_weight * bce\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        prob = torch.sigmoid(logits)\n",
        "        num = 2 * (prob * targets).sum(dim=-1)\n",
        "        den = prob.sum(dim=-1) + targets.sum(dim=-1)\n",
        "        loss = 1 - (num + self.eps) / (den + self.eps)\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "# combined loss wrapper\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, weight_mask=1.0, weight_global=1.0, alpha=0.25, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.focal = FocalLoss(alpha=alpha, gamma=gamma)\n",
        "        self.dice = DiceLoss()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.w_mask = weight_mask\n",
        "        self.w_global = weight_global\n",
        "\n",
        "    def forward(self, mask_logits, mask_targets, global_logits, global_targets):\n",
        "        # mask_targets: (B, n)  global_targets: (B,)  both 0/1\n",
        "        focal_loss = self.focal(mask_logits, mask_targets)\n",
        "        dice_loss = self.dice(mask_logits, mask_targets)\n",
        "        mask_loss = 0.7 * focal_loss + 0.3 * dice_loss  # semantic + focal blended\n",
        "\n",
        "        global_loss = self.bce(global_logits, global_targets.float())\n",
        "\n",
        "        return self.w_mask * mask_loss + self.w_global * global_loss, {\n",
        "            'mask_focal': focal_loss.item(),\n",
        "            'mask_dice': dice_loss.item(),\n",
        "            'global_bce': global_loss.item(),\n",
        "        }\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Example training step (skeleton)\n",
        "# -----------------------------\n",
        "\n",
        "def training_step(model: nn.Module, batch, optimizer, loss_fn, device='cpu'):\n",
        "    model.train()\n",
        "    dist, plm, pae, mask_targets, global_targets, names = batch\n",
        "\n",
        "    dist = dist.to(device)\n",
        "    plm = plm.to(device)\n",
        "    pae = pae.to(device)\n",
        "    mask_targets = mask_targets.to(device)\n",
        "    global_targets = global_targets.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    mask_logits, global_logits = model(dist, plm, pae)\n",
        "    loss, stats = loss_fn(mask_logits, mask_targets, global_logits, global_targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), stats\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# How to instantiate and run\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    base_path = '/content/drive/MyDrive/CLAPE-RESULTS'\n",
        "    ds = CLAPEDataset(\n",
        "        dist_dir=os.path.join(base_path, 'af-distancemaps'),\n",
        "        plm_dir=os.path.join(base_path, 'transformed_matrices'),\n",
        "        pae_dir=os.path.join(base_path, 'PAE-MATRICES'),\n",
        "        label_csv=os.path.join(base_path, 'binding_sites_uniprot.csv')\n",
        "    )\n",
        "    dl = DataLoader(ds, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = BindingAffinityNet(base_channels=32, num_heads=8, K=5).to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    loss_fn = CombinedLoss()\n",
        "\n",
        "    for i, batch in enumerate(dl):\n",
        "        loss, stats = training_step(model, batch, opt, loss_fn, device)\n",
        "        print(f\"iter {i} loss={loss:.4f}\", stats)\n",
        "        if i >= 5:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "C0r1FW-upTsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/CLAPE-RESULTS'\n",
        "\n",
        "ds = CLAPEDataset(\n",
        "    dist_dir=os.path.join(base_path, 'af-distancemaps'),\n",
        "    plm_dir=os.path.join(base_path, 'transformed_matrices'),\n",
        "    pae_dir=os.path.join(base_path, 'PAE-MATRICES'),\n",
        "    label_csv=os.path.join(base_path, 'binding_sites_uniprot.csv'),\n",
        "    file_list=['P16234-F1-model_v4']\n",
        "\n",
        "sample = ds[0]\n",
        "for x in sample:\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        print(x.shape)\n",
        "    else:\n",
        "        print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIqj7ZEjeXxe",
        "outputId": "8c9c782b-b2d4-42d5-9c52-5488f26a2ee5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1200, 1200])\n",
            "torch.Size([1, 1200, 1200])\n",
            "torch.Size([1, 1200, 1200])\n",
            "torch.Size([1200])\n",
            "torch.Size([])\n",
            "P16234-F1-model_v4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)\n",
        "batch = next(iter(dl))\n",
        "for b in batch:\n",
        "    if isinstance(b, torch.Tensor):\n",
        "        print(b.shape)\n",
        "    else:\n",
        "        print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k33lvojpfHqz",
        "outputId": "22b05c6a-17a1-4bc7-c0a4-86684601b564"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 1200, 1200])\n",
            "torch.Size([1, 1, 1200, 1200])\n",
            "torch.Size([1, 1, 1200, 1200])\n",
            "torch.Size([1, 1200])\n",
            "torch.Size([1])\n",
            "('P16234-F1-model_v4',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "JVOF_bKCfwhj",
        "outputId": "6ec9d3e4-0f33-4e21-8277-ee198b2a6ad6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dist' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3000461754.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = BindingAffinityNet(base_channels=8, num_heads=2, K=3).to(device)\n",
        "dist, plm, pae, mask, global_label, name = [b.to(device) if isinstance(b, torch.Tensor) else b for b in batch]\n",
        "print(dist.shape, plm.shape, pae.shape)\n",
        "print(torch.isnan(dist).any(), torch.isinf(dist).any())\n",
        "print(torch.isnan(plm).any(), torch.isinf(plm).any())\n",
        "print(torch.isnan(pae).any(), torch.isinf(pae).any())\n",
        "print(dist.device,next(model.parameters()).device)\n",
        "\n",
        "dist_small = dist[:, :, :20, :20]\n",
        "plm_small = plm[:, :, :20, :20]\n",
        "pae_small = pae[:, :, :20, :20]\n",
        "\n",
        "with torch.no_grad():\n",
        "    mask_logits, global_logits = model(dist_small, plm_small, pae_small)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1-lJRE3fb0h",
        "outputId": "cb2decdd-1711-4b85-b451-ee19ea17baf2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 1200, 1200]) torch.Size([1, 1, 1200, 1200]) torch.Size([1, 1, 1200, 1200])\n",
            "tensor(False) tensor(False)\n",
            "tensor(False) tensor(False)\n",
            "tensor(False) tensor(False)\n",
            "cpu cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import glob\n",
        "importlib.reload(glob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te32fp3VmH4U",
        "outputId": "c7be51a2-d9f2-4794-f7ae-8baa84c2efe3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'glob' from '/usr/lib/python3.12/glob.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Minimal test training loop\n",
        "# -----------------------------\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Instantiate model and loss\n",
        "model = BindingAffinityNet(base_channels=8, num_heads=2, K=3).to(device)\n",
        "loss_fn = CombinedLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Use your small batch (dist_small etc.)\n",
        "dist_small = dist[:, :, :20, :20]\n",
        "plm_small = plm[:, :, :20, :20]\n",
        "pae_small = pae[:, :, :20, :20]\n",
        "n_small = dist_small.shape[-1]\n",
        "mask_small = mask[:, :n_small]        # ensure same size\n",
        "global_small = global_label\n",
        "\n",
        "dist_small = dist_small.to(device)\n",
        "plm_small = plm_small.to(device)\n",
        "pae_small = pae_small.to(device)\n",
        "mask_small = mask_small.to(device)\n",
        "global_small = global_small.to(device)\n",
        "\n",
        "\n",
        "# Run a few steps\n",
        "for step in range(5):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    mask_logits, global_logits = model(dist_small, plm_small, pae_small)\n",
        "    loss, stats = loss_fn(mask_logits, mask_small, global_logits, global_small)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Step {step} | Loss: {loss.item():.4f} | \"\n",
        "          f\"mask_focal: {stats['mask_focal']:.4f}, \"\n",
        "          f\"mask_dice: {stats['mask_dice']:.4f}, \"\n",
        "          f\"global_bce: {stats['global_bce']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3bDZPVxieWC",
        "outputId": "f340ff28-8690-406c-a5d1-d3d4c94e956d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0 | Loss: 1.0479 | mask_focal: 0.0908, mask_dice: 1.0000, global_bce: 0.6843\n",
            "Step 1 | Loss: 1.0416 | mask_focal: 0.0844, mask_dice: 1.0000, global_bce: 0.6825\n",
            "Step 2 | Loss: 1.0376 | mask_focal: 0.0814, mask_dice: 1.0000, global_bce: 0.6806\n",
            "Step 3 | Loss: 1.0345 | mask_focal: 0.0796, mask_dice: 1.0000, global_bce: 0.6788\n",
            "Step 4 | Loss: 1.0326 | mask_focal: 0.0796, mask_dice: 1.0000, global_bce: 0.6769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYn7aMQyXZBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}